{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from frameit.corpus import Corpus\n",
    "from frameit.utils import *\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the positive set of a frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is necessary for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'frame_training_info.json'\n",
    "positive_utterances = load_frame_pos_set(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the part of speech and dependencies that correspond to the attribute you are trying to extract.\n",
    "#You will be able to provide more detailed information to extract attributes later\n",
    "#name: str, the attribute's name, used to identify it\n",
    "#linguistic_info: dict, keys are POS, DEP, and lemma. Values are lists of spacy part-of-speech and dependency tags\n",
    "#(for POS and DEP) and a list of strings for lemma. If values are passed for a key, only attributes matching those\n",
    "#values will be extracted by the model.\n",
    "#unique: bool, if True only one attribute will be extracted per sentence using this model\n",
    "proper_noun_attr = {\"name\": \"Proper Noun Attribute\", \n",
    "                    \"linguistic_info\": {\"POS\": [\"PROPN\"]}, \n",
    "                    \"unique\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative method of attribute extraction: lambda rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda rules are functions that are added to an attribute and called when a sentence is passed to the frame for classification\n",
    "#They can include any heuristic you want, but need to import any dependencies inside the function\n",
    "#The function is passed to the attribute when calling its training function\n",
    "#(this notebook saves the function to a json file from which the training script can load it)\n",
    "#The following is an example heuristic that extracts proper nouns.\n",
    "def get_prop_name(doc):\n",
    "    from frameit import TextProcessing\n",
    "    tp = TextProcessing()\n",
    "    src_cand = tp.extract_candidates_by_parent(doc, \n",
    "                                               [{}], [{\"pos\":[\"propn\"]}])\n",
    "    src_cand_tokens = []\n",
    "    for (_, sp, sent) in src_cand:\n",
    "        if sp is not None:\n",
    "            for t in sp:\n",
    "                src_cand_tokens.append(t)\n",
    "    return src_cand_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should test your lambda rule function on utterances from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    sent = positive_utterances.pop()\n",
    "    print(sent.text)\n",
    "    print(get_prop_name(sent.spacy))\n",
    "    print('/n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the frame and attribute data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'attr2.json'\n",
    "save_lambda_attr_data_to_file(proper_noun_attr, get_prop_name, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
