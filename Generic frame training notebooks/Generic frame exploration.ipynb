{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from frameit.corpus import Corpus\n",
    "from frameit.utils import *\n",
    "from frameit.drop_gold_from_train import dropGold\n",
    "from frameit.EvalAFrame import evalFrame\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These notebooks are set up to train a frame that can detect sentences about meals. Feel free to replace the default data files and modify the code as needed to adapt these notebooks to your purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your corpus should be in a .csv file, and the text to be used as training should be in a column titled \"text\", with each data point on a separate line. If you are planning on using a gold set, you should also have an \"Index\" column with id numbers for each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"../resources/happy_moment_corpus_small.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: set up a gold set and drop it from the training file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a gold set of positive and negative examples in an XML file, you can drop those examples from\n",
    "the training data with the following code.\n",
    "\n",
    "See the instructions in docs/evaluation.rst for more information on formatting data for the evaluation script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If your positive and negative gold examples are in the same file, you can\n",
    "#pass that file to both parametersâ€“positive examples in the negative file and negative examples in the positive file\n",
    "#will simply be ignored\n",
    "positive_example_file = '../resources/meal_gold_set.xml'\n",
    "negative_example_file = '../resources/meal_gold_set.xml'\n",
    "#Note: for the default data set which is abnormally small, we use a sample size of 5. For your own purposes,\n",
    "#we recommend using at least 100 examples.\n",
    "corpus_file, gold_file = dropGold(corpus_file, positive_example_file, negative_example_file, prefix=\"../resources/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Corpus data should have one sentence per line in a column titled \"text\". Additionally, there should be a column titled\n",
    "#\"index\" containing the row number of the datapoint (row numbers do not need to be accurate for the .csv file, but\n",
    "#they do need to be unique.)\n",
    "#When loading a new corpus for the first time, set build_index to True to create indices necessary to process the data.\n",
    "#Otherwise, this step can be safely skipped to significantly speed up runtime by setting build_index to False\n",
    "corpus = Corpus(corpus_file, build_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a positive set for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A starting point for the positive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_strings = ['example', 'strings', 'that would be in the', 'positive', 'sentences', 'for', 'the intent',\n",
    "#                    'that you want', 'to extract']\n",
    "positive_strings = ['breakfast', 'brunch', 'lunch', 'dinner']\n",
    "positive_utterances = build_positive_set(corpus, positive_strings)\n",
    "#Note: for exact matches of the strings, use the above function call to build_positive_set(). \n",
    "#To also include matches of all tenses and plural/singular forms of all words in the string, add_lemmas_to_set()\n",
    "lemma_strings = ['restaurant', 'cafe']\n",
    "positive_utterances = add_lemmas_to_set(corpus, lemma_strings, existing_set=positive_utterances)\n",
    "negative_set = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: expand using hypernyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hypernym h of a word w is a more generic term that includes w as part of its semantic field. \n",
    "For example, \"bird\" is a hypernym of \"pigeon\", \"eagle\", \"falcon\", etc. \"Animal\" is a hypernym of \"bird\".\n",
    "\n",
    "Expanding with hypernyms may not always be appropriate. You may also want to use a different set of terms than \n",
    "the full list of positive_strings defined earlier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_utterances = expand_with_hypernym(positive_utterances, positive_strings, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample sentences to check positive set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in random.sample(positive_utterances, 20):\n",
    "    print(a.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming the positive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove bad examples from the positive set. Also creates a negative set that can optionally be used\n",
    "#Note: there may not necessarily be any bad examples to trim, in which case you should skip this step.\n",
    "remove_list = ['strings', 'that occur', 'in the positive set', 'that correspond', 'to examples',\n",
    "               'that are not positive']\n",
    "positive_utterances, negative_set = trim_examples(positive_utterances, remove_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify hyperparameters for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, you can customize hyperparameters for the training function. Otherwise, the function will be run with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_to=700\n",
    "epochs=40\n",
    "batch_size=1400\n",
    "reg_param=0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the frame a name and save it to a file\n",
    "frame_info_filename = 'frame_training_info.json'\n",
    "frame_name = \"Your Frame Name\"\n",
    "save_frame_training_info_to_file(frame_name, corpus_file, positive_utterances, negative_set,\n",
    "                                scale_to, epochs, batch_size, reg_param, frame_info_filename, gold_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that running the above code saves your training data set as an XML file titled \"resources/Your Frame Name_interim_data.xml\" (if you change the frame_name variable, it will use whatever string you've set there instead of \"Your Frame Name\"). If you like, you can edit the data set by hand in that file; the file will be used in the Train frame notebook to train your frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop here and use *Generic lambda_rule attribute exploration.ipynb* and/or *Generic machine-learning attribute exploration.ipynb* if you would like to train attributes for entity-extraction to be used with this frame. When you've collected the necessary data for attributes that you want to train, proceed to the *Train frame* notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
