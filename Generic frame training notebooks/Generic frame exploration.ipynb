{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the en model\n",
      "\n",
      "    \u001b[93mInfo about spaCy\u001b[0m\n",
      "\n",
      "    spaCy version      2.0.11         \n",
      "    Location           /home/ubuntu/miniconda3/envs/dev_framers/lib/python3.6/site-packages/spacy\n",
      "    Platform           Linux-4.4.0-1049-aws-x86_64-with-debian-stretch-sid\n",
      "    Python version     3.6.5          \n",
      "    Models             en_core_web_lg, en, fr\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from frameit.corpus import Corpus\n",
    "from frameit.utils import *\n",
    "from frameit.drop_gold_from_train import dropRepeats\n",
    "from frameit.EvalAFrame import evalFrame\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"./resources/ty_data/questions/qa_questions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you have a gold set of positive and negative examples in an XML file, you can drop those examples from\n",
    "#the training data with the following code. If your positive and negative gold examples are in the same file, you can\n",
    "#pass that file to both parameters–positive examples in the negative file and negative examples in the positive file\n",
    "#will simply be ignored\n",
    "positive_example_file = 'gold_positive.xml'\n",
    "negative_example_file = 'gold_negative.xml'\n",
    "corpus_file, gold_file = dropRepeats(corpus_file, positive_example_file, negative_example_file, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init Corpus\n",
      "Parsing the Semafor data... \n",
      "Parsing the DeepSRL data... \n",
      "Creating Utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Dev_FrameIt2/FrameIt2/frameit/corpus.py:54: UserWarning: No FrameNet data found for the corpus.\n",
      "  warnings.warn('No FrameNet data found for the corpus.')\n",
      "/home/ubuntu/Dev_FrameIt2/FrameIt2/frameit/corpus.py:64: UserWarning: No ProbBank data found for the corpus.\n",
      "  warnings.warn('No ProbBank data found for the corpus.')\n",
      "100%|██████████| 31740/31740 [00:00<00:00, 150240.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading indices...\n",
      "Loading lemma indices...\n"
     ]
    }
   ],
   "source": [
    "#Corpus data should have one sentence per line in a column titled \"text\". Any other columns will be ignored\n",
    "#When loading a new corpus for the first time, set build_index to True to create indices necessary to process the data.\n",
    "#Otherwise, this step can be safely skipped to significantly speed up runtime by setting build_index to False\n",
    "corpus = Corpus(corpus_file, build_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a positive set for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A starting point for the positive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5187 relevant messages in the corpus\n",
      "There are 5241 relevant messages in the corpus\n"
     ]
    }
   ],
   "source": [
    "positive_strings = ['example', 'strings', 'that would be in the', 'positive', 'sentences', 'for', 'the intent',\n",
    "                   'that you want', 'to extract']\n",
    "# positive_strings = ['open', 'close', 'when', 'hours', 'late', 'early']\n",
    "positive_utterances = build_positive_set(corpus, positive_strings)\n",
    "#Note: for exact matches of the strings, use the above function call to build_positive_set(). \n",
    "#To also include matches of all tenses and plural/singular forms of all words in the string, add_lemmas_to_set()\n",
    "lemma_strings = ['run', 'dance']\n",
    "positive_utterances = add_lemmas_to_set(corpus, lemma_strings, existing_set=positive_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: expand using hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strings\n",
      "that would be in the\n",
      "positive\n",
      "sentences\n",
      "for\n",
      "the intent\n",
      "that you want\n",
      "to extract\n",
      "Number of strings for which no hypernyms were found  8\n",
      "case\n",
      "example\n",
      "time\n",
      "tasting\n",
      "There are 6003 relevant messages in the corpus\n"
     ]
    }
   ],
   "source": [
    "#A hypernym h of a word w is a more generic term that includes w as part of its semantic field. \n",
    "#For example, \"bird\" is a hypernym of \"pigeon\", \"eagle\", \"falcon\", etc. \"Animal\" is a hypernym of \"bird\".\n",
    "\n",
    "#Expanding with hypernyms may not always be appropriate. You may also want to use a different set of terms than \n",
    "#the full list of positive_strings defined earlier\n",
    "\n",
    "positive_utterances = expand_with_hypernym(positive_utterances, positive_strings, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample sentences to check positive set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are getting brunch in the area so we are staying parked in the garage for about another hours or so, is that okay?\n",
      "\n",
      "tell me the user name for wifi?\n",
      "\n",
      "Is there a charge for WiFi?\n",
      "\n",
      "Could we organize for a taxi to take us to the airport at 12:45?\n",
      "\n",
      "Do you have any vases for flowers I can borrow?\n",
      "\n",
      "Is there any chance for a late check-out of 2pm tomorrow?\n",
      "\n",
      "Can we arrange for an early check in?\n",
      "\n",
      "may i request for early check in tomorrow?\n",
      "\n",
      "Can I get a reservation for 2 at Marsh House tonight 7pm please?\n",
      "\n",
      "Do you have any for purchase?\n",
      "\n",
      "Was there anything special needed for checkout?\n",
      "\n",
      "Can I pre-authorize a credit card for incidentals?\n",
      "\n",
      "be able to assist in getting a rental car or zip car type of thing for this afternoon?\n",
      "\n",
      "Is it possible to order espn for the apartment so we can watch the us open?\n",
      "\n",
      "Is there anyway we can switch for today?\n",
      "\n",
      "Is there anyway I can have a room close to guests staying for the wedding?\n",
      "\n",
      "Do you ask for security deposits or is that included in the nightly cost?\n",
      "\n",
      "Do you have the new hotel info for me?\n",
      "\n",
      "Would someone be able to schedule this for us?\n",
      "\n",
      "tell when check out time is this morning?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in random.sample(positive_utterances, 20):\n",
    "    print(a.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming the positive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6003 relevant messages in the corpus\n"
     ]
    }
   ],
   "source": [
    "#To remove bad examples from the positive set. Also creates a negative set that can optionally be used\n",
    "remove_list = ['strings', 'that occur', 'in the positive set', 'that correspond', 'to examples',\n",
    "               'that are not positive']\n",
    "positive_utterances, negative_set = trim_examples(positive_utterances, remove_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify hyperparameters for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, you can customize hyperparameters for the training function. Otherwise, the function will be run with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_to=700\n",
    "epochs=40\n",
    "batch_size=1400\n",
    "reg_param=0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved info with filename frame_training_info.json.\n"
     ]
    }
   ],
   "source": [
    "# Give the frame a name and save it to a file\n",
    "frame_filename = 'frame_training_info.json'\n",
    "frame_name = \"Your Frame Name\"\n",
    "save_frame_training_info_to_file(frame_name, corpus_file, positive_utterances, negative_set,\n",
    "                                scale_to, epochs, batch_size, reg_param, frame_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init Corpus\n",
      "Parsing the Semafor data... \n",
      "Parsing the DeepSRL data... \n",
      "Creating Utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Dev_FrameIt2/FrameIt2/frameit/corpus.py:54: UserWarning: No FrameNet data found for the corpus.\n",
      "  warnings.warn('No FrameNet data found for the corpus.')\n",
      "/home/ubuntu/Dev_FrameIt2/FrameIt2/frameit/corpus.py:64: UserWarning: No ProbBank data found for the corpus.\n",
      "  warnings.warn('No ProbBank data found for the corpus.')\n",
      "100%|██████████| 31740/31740 [00:00<00:00, 92274.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading indices...\n",
      "Loading lemma indices...\n",
      "Importing machine learning attributes\n",
      "Training  Attribute 1\n",
      "Importing lambda_rule attributes\n",
      "Training  Proper Noun Attribute\n",
      "Rebuilding frame\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/dev_framers/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Train on 10806 samples, validate on 1200 samples\n",
      "Epoch 1/40\n",
      "10806/10806 [==============================] - 3s 286us/step - loss: 11.9798 - acc: 0.5747 - val_loss: 10.2931 - val_acc: 0.6142\n",
      "Epoch 2/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 9.2145 - acc: 0.6244 - val_loss: 7.8557 - val_acc: 0.6242\n",
      "Epoch 3/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 7.0080 - acc: 0.6368 - val_loss: 5.9523 - val_acc: 0.6342\n",
      "Epoch 4/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 5.2971 - acc: 0.6700 - val_loss: 4.4825 - val_acc: 0.7108\n",
      "Epoch 5/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 3.9614 - acc: 0.7865 - val_loss: 3.3208 - val_acc: 0.8350\n",
      "Epoch 6/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 2.9575 - acc: 0.8439 - val_loss: 2.5157 - val_acc: 0.8700\n",
      "Epoch 7/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 2.2433 - acc: 0.8692 - val_loss: 1.9262 - val_acc: 0.8858\n",
      "Epoch 8/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 1.7339 - acc: 0.8899 - val_loss: 1.5071 - val_acc: 0.8933\n",
      "Epoch 9/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 1.3642 - acc: 0.8948 - val_loss: 1.2059 - val_acc: 0.8900\n",
      "Epoch 10/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 1.0966 - acc: 0.8973 - val_loss: 0.9842 - val_acc: 0.8975\n",
      "Epoch 11/40\n",
      "10806/10806 [==============================] - 3s 246us/step - loss: 0.9047 - acc: 0.8969 - val_loss: 0.8235 - val_acc: 0.8983\n",
      "Epoch 12/40\n",
      "10806/10806 [==============================] - 3s 249us/step - loss: 0.7620 - acc: 0.8999 - val_loss: 0.7061 - val_acc: 0.8983\n",
      "Epoch 13/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.6595 - acc: 0.9001 - val_loss: 0.6214 - val_acc: 0.8992\n",
      "Epoch 14/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.5848 - acc: 0.9010 - val_loss: 0.5631 - val_acc: 0.8975\n",
      "Epoch 15/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.5333 - acc: 0.9013 - val_loss: 0.5157 - val_acc: 0.8983\n",
      "Epoch 16/40\n",
      "10806/10806 [==============================] - 3s 246us/step - loss: 0.4917 - acc: 0.9018 - val_loss: 0.4835 - val_acc: 0.8992\n",
      "Epoch 17/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.4662 - acc: 0.8993 - val_loss: 0.4638 - val_acc: 0.9025\n",
      "Epoch 18/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 0.4445 - acc: 0.9014 - val_loss: 0.4426 - val_acc: 0.9017\n",
      "Epoch 19/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 0.4286 - acc: 0.9022 - val_loss: 0.4271 - val_acc: 0.8992\n",
      "Epoch 20/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.4143 - acc: 0.9029 - val_loss: 0.4170 - val_acc: 0.8992\n",
      "Epoch 21/40\n",
      "10806/10806 [==============================] - 3s 246us/step - loss: 0.4051 - acc: 0.9019 - val_loss: 0.4141 - val_acc: 0.9033\n",
      "Epoch 22/40\n",
      "10806/10806 [==============================] - 3s 246us/step - loss: 0.3971 - acc: 0.9032 - val_loss: 0.4085 - val_acc: 0.8975\n",
      "Epoch 23/40\n",
      "10806/10806 [==============================] - 3s 246us/step - loss: 0.3929 - acc: 0.9026 - val_loss: 0.4042 - val_acc: 0.8958\n",
      "Epoch 24/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.3961 - acc: 0.8998 - val_loss: 0.4018 - val_acc: 0.9033\n",
      "Epoch 25/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 0.3882 - acc: 0.9032 - val_loss: 0.3964 - val_acc: 0.9033\n",
      "Epoch 26/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.3822 - acc: 0.9037 - val_loss: 0.3874 - val_acc: 0.8992\n",
      "Epoch 27/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 0.3776 - acc: 0.9024 - val_loss: 0.3875 - val_acc: 0.9033\n",
      "Epoch 28/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 0.3748 - acc: 0.9038 - val_loss: 0.3829 - val_acc: 0.8992\n",
      "Epoch 29/40\n",
      "10806/10806 [==============================] - 3s 249us/step - loss: 0.3720 - acc: 0.9034 - val_loss: 0.3817 - val_acc: 0.9017\n",
      "Epoch 30/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.3691 - acc: 0.9037 - val_loss: 0.3785 - val_acc: 0.9017\n",
      "Epoch 31/40\n",
      "10806/10806 [==============================] - 3s 246us/step - loss: 0.3677 - acc: 0.9040 - val_loss: 0.3769 - val_acc: 0.9025\n",
      "Epoch 32/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 0.3659 - acc: 0.9035 - val_loss: 0.3751 - val_acc: 0.9033\n",
      "Epoch 33/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.3639 - acc: 0.9041 - val_loss: 0.3741 - val_acc: 0.9033\n",
      "Epoch 34/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.3632 - acc: 0.9047 - val_loss: 0.3729 - val_acc: 0.9000\n",
      "Epoch 35/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 0.3628 - acc: 0.9038 - val_loss: 0.3707 - val_acc: 0.9042\n",
      "Epoch 36/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 0.3600 - acc: 0.9041 - val_loss: 0.3728 - val_acc: 0.9042\n",
      "Epoch 37/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 0.3621 - acc: 0.9028 - val_loss: 0.3690 - val_acc: 0.9008\n",
      "Epoch 38/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.3582 - acc: 0.9040 - val_loss: 0.3686 - val_acc: 0.9050\n",
      "Epoch 39/40\n",
      "10806/10806 [==============================] - 3s 248us/step - loss: 0.3582 - acc: 0.9035 - val_loss: 0.3675 - val_acc: 0.9050\n",
      "Epoch 40/40\n",
      "10806/10806 [==============================] - 3s 247us/step - loss: 0.3581 - acc: 0.9042 - val_loss: 0.3667 - val_acc: 0.9050\n",
      "Saving frame to file\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from frameit.train_from_exploration import train_frame_wrapper\n",
    "train_frame_wrapper(\"test_frame.json\", frame_file=frame_filename, ml_attr_files=[\"attr1.json\"], \n",
    "                    lambda_attr_files=[\"attr2.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the en model\n",
      "\n",
      "    \u001b[93mInfo about spaCy\u001b[0m\n",
      "\n",
      "    spaCy version      2.0.11         \n",
      "    Location           /home/ubuntu/miniconda3/envs/dev_framers/lib/python3.6/site-packages/spacy\n",
      "    Platform           Linux-4.4.0-1049-aws-x86_64-with-debian-stretch-sid\n",
      "    Python version     3.6.5          \n",
      "    Models             en_core_web_lg, en, fr\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for testing\n",
    "from frameit import SRL, Frame\n",
    "srl = SRL()\n",
    "frame = Frame.load('test_frame.json')\n",
    "srl.addFrame(frame)\n",
    "srl.parse('Where is the pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl.parse('Where is the pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalFrame(frame_filename, gold_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_framers",
   "language": "python",
   "name": "dev_framers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
