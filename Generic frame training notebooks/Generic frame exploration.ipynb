{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jengelwork/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from frameit.corpus import Corpus\n",
    "from frameit.utils import *\n",
    "from frameit.drop_gold_from_train import dropRepeats\n",
    "from frameit.EvalAFrame import evalFrame\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_file = \"your_corpus.csv\"\n",
    "corpus_file = \"../../../conciergebot-api/data/ty_data/english_corpus/qa_questions_en.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you have a gold set of positive and negative examples in an XML file, you can drop those examples from\n",
    "#the training data with the following code. If your positive and negative gold examples are in the same file, you can\n",
    "#pass that file to both parameters–positive examples in the negative file and negative examples in the positive file\n",
    "#will simply be ignored\n",
    "positive_example_file = 'gold_positive.xml'\n",
    "negative_example_file = 'gold_negative.xml'\n",
    "corpus_file, gold_file = dropRepeats(corpus_file, positive_example_file, negative_example_file, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init Corpus\n",
      "Parsing the Semafor data... \n",
      "Parsing the DeepSRL data... \n",
      "Creating Utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jengelwork/Documents/FrameItExport/frameit/frameit/corpus.py:54: UserWarning: No FrameNet data found for the corpus.\n",
      "  warnings.warn('No FrameNet data found for the corpus.')\n",
      "/Users/jengelwork/Documents/FrameItExport/frameit/frameit/corpus.py:64: UserWarning: No ProbBank data found for the corpus.\n",
      "  warnings.warn('No ProbBank data found for the corpus.')\n",
      "  0%|          | 0/31740 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the en model\n",
      "\n",
      "    \u001b[93mInfo about spaCy\u001b[0m\n",
      "\n",
      "    spaCy version      2.0.12         \n",
      "    Location           /Users/jengelwork/miniconda3/lib/python3.6/site-packages/spacy\n",
      "    Platform           Darwin-17.7.0-x86_64-i386-64bit\n",
      "    Python version     3.6.1          \n",
      "    Models             en_core_web_md, en_core_web_lg, fr, en, fr_core_news_sm\n",
      "\n",
      "\n",
      "    \u001b[93mInfo about spaCy\u001b[0m\n",
      "\n",
      "    spaCy version      2.0.12         \n",
      "    Location           /Users/jengelwork/miniconda3/lib/python3.6/site-packages/spacy\n",
      "    Platform           Darwin-17.7.0-x86_64-i386-64bit\n",
      "    Python version     3.6.1          \n",
      "    Models             en_core_web_md, en_core_web_lg, fr, en, fr_core_news_sm\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31740/31740 [00:11<00:00, 2747.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading indices...\n",
      "Loading lemma indices...\n"
     ]
    }
   ],
   "source": [
    "#Corpus data should have one sentence per line in a column titled \"text\". Any other columns will be ignored\n",
    "#When loading a new corpus for the first time, set build_index to True to create indices necessary to process the data.\n",
    "#Otherwise, this step can be safely skipped to significantly speed up runtime by setting build_index to False\n",
    "corpus = Corpus(corpus_file, build_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a positive set for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A starting point for the positive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4440 relevant messages in the corpus\n",
      "There are 4500 relevant messages in the corpus\n"
     ]
    }
   ],
   "source": [
    "positive_strings = ['example', 'strings', 'that would be in the', 'positive', 'sentences', 'for', 'the intent',\n",
    "                   'that you want', 'to extract']\n",
    "# positive_strings = ['open', 'close', 'when', 'hours', 'late', 'early']\n",
    "positive_utterances = build_positive_set(corpus, positive_strings)\n",
    "#Note: for exact matches of the strings, use the above function call to build_positive_set(). \n",
    "#To also include matches of all tenses and plural/singular forms of all words in the string, add_lemmas_to_set()\n",
    "lemma_strings = ['run', 'dance']\n",
    "positive_utterances = add_lemmas_to_set(corpus, lemma_strings, existing_set=positive_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: expand using hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when\n",
      "late\n",
      "early\n",
      "Number of strings for which no hypernyms were found  3\n",
      "go\n",
      "last\n",
      "open\n",
      "close\n",
      "There are 4891 relevant messages in the corpus\n"
     ]
    }
   ],
   "source": [
    "#A hypernym h of a word w is a more generic term that includes w as part of its semantic field. \n",
    "#For example, \"bird\" is a hypernym of \"pigeon\", \"eagle\", \"falcon\", etc. \"Animal\" is a hypernym of \"bird\".\n",
    "\n",
    "#Expanding with hypernyms may not always be appropriate. You may also want to use a different set of terms than \n",
    "#the full list of positive_strings defined earlier\n",
    "\n",
    "positive_utterances = expand_with_hypernym(positive_utterances, positive_strings, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample sentences to check positive set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will there still be valet space and open front desk?\n",
      "\n",
      "Can we check in early tomorrow?\n",
      "\n",
      "Is it possible to check in early?\n",
      "\n",
      "Could I move when I return around 6:30pm?\n",
      "\n",
      "confirm I am scheduled for late checkout?\n",
      "\n",
      "do early check in at 1 pm for those rooms?\n",
      "\n",
      "Can we leave our car in the garage and pick it up in a few hours?\n",
      "\n",
      "verify when a crib will be able to be brought up?\n",
      "\n",
      "Is it possible for me to check out late on this coming Sunday?\n",
      "\n",
      "Is there any way we can get a late checkout?\n",
      "\n",
      "I have a reservation today..is it possible to check in early?\n",
      "\n",
      "Can I get a late check out, please?\n",
      "\n",
      "Is there a chance we can have a late checkout tomorrow?\n",
      "\n",
      "Do you think we would be able to have early check in?\n",
      "\n",
      "is late check out available for tomorrow?\n",
      "\n",
      "can I do a late checkout?\n",
      "\n",
      "do I do anything special to the apartment or leave the fob and go?\n",
      "\n",
      "is it possible to get a late checkout tomorrow?\n",
      "\n",
      "Is there any availability on early check ins?\n",
      "\n",
      "this is Mr. Hunter in room 1250. tell me the wifi login information and what time the hot tubs close?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in random.sample(positive_utterances, 20):\n",
    "    print(a.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming the positive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4891 relevant messages in the corpus\n"
     ]
    }
   ],
   "source": [
    "#To remove bad examples from the positive set. Also creates a negative set that can optionally be used\n",
    "remove_list = ['strings', 'that occur', 'in the positive set', 'that correspond', 'to examples',\n",
    "               'that are not positive']\n",
    "positive_utterances, negative_set = trim_examples(positive_utterances, remove_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify hyperparameters for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, you can customize hyperparameters for the training function. Otherwise, the function will be run with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_to=700\n",
    "epochs=40\n",
    "batch_size=1400\n",
    "reg_param=0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved info with filename frame_training_info.json.\n"
     ]
    }
   ],
   "source": [
    "# Give the frame a name and save it to a file\n",
    "frame_filename = 'frame_training_info.json'\n",
    "frame_name = \"Your Frame Name\"\n",
    "save_frame_training_info_to_file(frame_name, corpus_file, positive_utterances, negative_set,\n",
    "                                scale_to, epochs, batch_size, reg_param, frame_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop here and use *Generic lambda_rule attribute exploration.ipynb* and/or *Generic machine-learning attribute exploration.ipynb* if you would like to train attributes for entity-extraction to be used with this frame. When you've collected the necessary data for attributes that you want to train, run the following cell to train a frame, adjusting passed parameters as necessary to incorporate your attribute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init Corpus\n",
      "Parsing the Semafor data... \n",
      "Parsing the DeepSRL data... \n",
      "Creating Utterances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jengelwork/Documents/FrameItExport/frameit/frameit/corpus.py:54: UserWarning: No FrameNet data found for the corpus.\n",
      "  warnings.warn('No FrameNet data found for the corpus.')\n",
      "/Users/jengelwork/Documents/FrameItExport/frameit/frameit/corpus.py:64: UserWarning: No ProbBank data found for the corpus.\n",
      "  warnings.warn('No ProbBank data found for the corpus.')\n",
      "100%|██████████| 31740/31740 [00:00<00:00, 33162.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading indices...\n",
      "Loading lemma indices...\n",
      "Importing machine learning attributes\n",
      "Training  Attribute 1\n",
      "Importing lambda_rule attributes\n",
      "Training  Proper Noun Attribute\n",
      "Rebuilding frame\n",
      "Train on 8804 samples, validate on 978 samples\n",
      "Epoch 1/40\n",
      "8804/8804 [==============================] - 8s 866us/step - loss: 12.1831 - acc: 0.6181 - val_loss: 10.5634 - val_acc: 0.6902\n",
      "Epoch 2/40\n",
      "8804/8804 [==============================] - 5s 573us/step - loss: 9.6822 - acc: 0.7066 - val_loss: 8.3345 - val_acc: 0.7382\n",
      "Epoch 3/40\n",
      "8804/8804 [==============================] - 5s 559us/step - loss: 7.6069 - acc: 0.7524 - val_loss: 6.5062 - val_acc: 0.7628\n",
      "Epoch 4/40\n",
      "8804/8804 [==============================] - 5s 568us/step - loss: 5.9304 - acc: 0.7661 - val_loss: 5.0743 - val_acc: 0.7894\n",
      "Epoch 5/40\n",
      "8804/8804 [==============================] - 5s 553us/step - loss: 4.6301 - acc: 0.7891 - val_loss: 3.9673 - val_acc: 0.8078\n",
      "Epoch 6/40\n",
      "8804/8804 [==============================] - 5s 584us/step - loss: 3.6291 - acc: 0.8176 - val_loss: 3.1280 - val_acc: 0.8487\n",
      "Epoch 7/40\n",
      "8804/8804 [==============================] - 5s 567us/step - loss: 2.8726 - acc: 0.8331 - val_loss: 2.4958 - val_acc: 0.8262\n",
      "Epoch 8/40\n",
      "8804/8804 [==============================] - 5s 586us/step - loss: 2.2883 - acc: 0.8480 - val_loss: 1.9948 - val_acc: 0.8671\n",
      "Epoch 9/40\n",
      "8804/8804 [==============================] - 5s 563us/step - loss: 1.8422 - acc: 0.8681 - val_loss: 1.6199 - val_acc: 0.8753\n",
      "Epoch 10/40\n",
      "8804/8804 [==============================] - 5s 582us/step - loss: 1.5014 - acc: 0.8774 - val_loss: 1.3338 - val_acc: 0.8783\n",
      "Epoch 11/40\n",
      "8804/8804 [==============================] - 5s 572us/step - loss: 1.2437 - acc: 0.8855 - val_loss: 1.1427 - val_acc: 0.8599\n",
      "Epoch 12/40\n",
      "8804/8804 [==============================] - 5s 564us/step - loss: 1.0607 - acc: 0.8832 - val_loss: 0.9654 - val_acc: 0.8896\n",
      "Epoch 13/40\n",
      "8804/8804 [==============================] - 5s 562us/step - loss: 0.9106 - acc: 0.8890 - val_loss: 0.8455 - val_acc: 0.8906\n",
      "Epoch 14/40\n",
      "8804/8804 [==============================] - 5s 561us/step - loss: 0.7957 - acc: 0.8985 - val_loss: 0.7498 - val_acc: 0.8926\n",
      "Epoch 15/40\n",
      "8804/8804 [==============================] - 5s 580us/step - loss: 0.7080 - acc: 0.9003 - val_loss: 0.6778 - val_acc: 0.9029\n",
      "Epoch 16/40\n",
      "8804/8804 [==============================] - 5s 568us/step - loss: 0.6427 - acc: 0.9045 - val_loss: 0.6247 - val_acc: 0.9018\n",
      "Epoch 17/40\n",
      "8804/8804 [==============================] - 5s 557us/step - loss: 0.5910 - acc: 0.9073 - val_loss: 0.5824 - val_acc: 0.9008\n",
      "Epoch 18/40\n",
      "8804/8804 [==============================] - 5s 574us/step - loss: 0.5516 - acc: 0.9080 - val_loss: 0.5519 - val_acc: 0.9080\n",
      "Epoch 19/40\n",
      "8804/8804 [==============================] - 5s 556us/step - loss: 0.5243 - acc: 0.9098 - val_loss: 0.5282 - val_acc: 0.9049\n",
      "Epoch 20/40\n",
      "8804/8804 [==============================] - 5s 557us/step - loss: 0.5010 - acc: 0.9099 - val_loss: 0.5237 - val_acc: 0.9049\n",
      "Epoch 21/40\n",
      "8804/8804 [==============================] - 5s 560us/step - loss: 0.4867 - acc: 0.9055 - val_loss: 0.4995 - val_acc: 0.9090\n",
      "Epoch 22/40\n",
      "8804/8804 [==============================] - 5s 570us/step - loss: 0.4680 - acc: 0.9124 - val_loss: 0.4757 - val_acc: 0.9070\n",
      "Epoch 23/40\n",
      "8804/8804 [==============================] - 6s 641us/step - loss: 0.4583 - acc: 0.9099 - val_loss: 0.4646 - val_acc: 0.9039\n",
      "Epoch 24/40\n",
      "8804/8804 [==============================] - 5s 601us/step - loss: 0.4458 - acc: 0.9130 - val_loss: 0.4609 - val_acc: 0.8978\n",
      "Epoch 25/40\n",
      "8804/8804 [==============================] - 5s 568us/step - loss: 0.4381 - acc: 0.9099 - val_loss: 0.4640 - val_acc: 0.9090\n",
      "Epoch 26/40\n",
      "8804/8804 [==============================] - 5s 564us/step - loss: 0.4352 - acc: 0.9128 - val_loss: 0.4405 - val_acc: 0.9131\n",
      "Epoch 27/40\n",
      "8804/8804 [==============================] - 5s 558us/step - loss: 0.4206 - acc: 0.9161 - val_loss: 0.4658 - val_acc: 0.8814\n",
      "Epoch 28/40\n",
      "8804/8804 [==============================] - 6s 630us/step - loss: 0.4208 - acc: 0.9100 - val_loss: 0.4322 - val_acc: 0.9070\n",
      "Epoch 29/40\n",
      "8804/8804 [==============================] - 5s 589us/step - loss: 0.4157 - acc: 0.9138 - val_loss: 0.4335 - val_acc: 0.9018\n",
      "Epoch 30/40\n",
      "8804/8804 [==============================] - 5s 571us/step - loss: 0.4123 - acc: 0.9136 - val_loss: 0.4282 - val_acc: 0.9090\n",
      "Epoch 31/40\n",
      "8804/8804 [==============================] - 5s 553us/step - loss: 0.4103 - acc: 0.9113 - val_loss: 0.4374 - val_acc: 0.9100\n",
      "Epoch 32/40\n",
      "8804/8804 [==============================] - 5s 556us/step - loss: 0.4063 - acc: 0.9153 - val_loss: 0.4184 - val_acc: 0.9080\n",
      "Epoch 33/40\n",
      "8804/8804 [==============================] - 5s 556us/step - loss: 0.3989 - acc: 0.9161 - val_loss: 0.4204 - val_acc: 0.9131\n",
      "Epoch 34/40\n",
      "8804/8804 [==============================] - 6s 633us/step - loss: 0.3974 - acc: 0.9146 - val_loss: 0.4150 - val_acc: 0.9141\n",
      "Epoch 35/40\n",
      "8804/8804 [==============================] - 5s 623us/step - loss: 0.3948 - acc: 0.9169 - val_loss: 0.4127 - val_acc: 0.9110\n",
      "Epoch 36/40\n",
      "8804/8804 [==============================] - 5s 613us/step - loss: 0.3910 - acc: 0.9171 - val_loss: 0.4189 - val_acc: 0.9018\n",
      "Epoch 37/40\n",
      "8804/8804 [==============================] - 5s 566us/step - loss: 0.3915 - acc: 0.9153 - val_loss: 0.4101 - val_acc: 0.9131\n",
      "Epoch 38/40\n",
      "8804/8804 [==============================] - 5s 567us/step - loss: 0.3870 - acc: 0.9165 - val_loss: 0.4065 - val_acc: 0.9121\n",
      "Epoch 39/40\n",
      "8804/8804 [==============================] - 5s 567us/step - loss: 0.3855 - acc: 0.9188 - val_loss: 0.4029 - val_acc: 0.9080\n",
      "Epoch 40/40\n",
      "8804/8804 [==============================] - 5s 623us/step - loss: 0.3820 - acc: 0.9187 - val_loss: 0.4058 - val_acc: 0.9049\n",
      "Saving frame to file\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from frameit.train_from_exploration import train_frame_wrapper\n",
    "train_frame_wrapper(\"test_frame.json\", frame_file=frame_filename, ml_attr_files=[\"attr1.json\"], \n",
    "                    lambda_attr_files=[\"attr2.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the en model\n",
      "\n",
      "    \u001b[93mInfo about spaCy\u001b[0m\n",
      "\n",
      "    spaCy version      2.0.12         \n",
      "    Location           /Users/jengelwork/miniconda3/lib/python3.6/site-packages/spacy\n",
      "    Platform           Darwin-17.7.0-x86_64-i386-64bit\n",
      "    Python version     3.6.1          \n",
      "    Models             en_core_web_md, en_core_web_lg, fr, en, fr_core_news_sm\n",
      "\n",
      "\n",
      "    \u001b[93mInfo about spaCy\u001b[0m\n",
      "\n",
      "    spaCy version      2.0.12         \n",
      "    Location           /Users/jengelwork/miniconda3/lib/python3.6/site-packages/spacy\n",
      "    Platform           Darwin-17.7.0-x86_64-i386-64bit\n",
      "    Python version     3.6.1          \n",
      "    Models             en_core_web_md, en_core_web_lg, fr, en, fr_core_news_sm\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for testing\n",
    "from frameit import SRL, Frame\n",
    "srl = SRL()\n",
    "frame = Frame.load('test_frame.json')\n",
    "srl.addFrame(frame)\n",
    "srl.parse('Where is the pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl.parse('Where is the pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gold_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a25f816ae479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevalFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gold_filename' is not defined"
     ]
    }
   ],
   "source": [
    "evalFrame(frame_filename, gold_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
